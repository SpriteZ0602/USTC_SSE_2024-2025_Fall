{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import SparkLLM\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考文档\n",
    "https://python.langchain.ac.cn/docs/integrations/llms/sparkllm/ \\\n",
    "推荐申请Spark Pro的免费token数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过api调用大模型\n",
    "llm = SparkLLM(\n",
    "    spark_app_id=\"spark_app_id\",\n",
    "    spark_api_key=\"spark_api_key\",\n",
    "    spark_api_secret=\"spark_api_secret\",\n",
    "    spark_api_url=\"wss://spark-api.xf-yun.com/v3.1/chat\",\n",
    "    model=\"generalv3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "###加载文件\n",
    "loader = PyPDFLoader(\"data/中国科学技术大学研究生学籍管理实施细则.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "###文本切分\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 300,chunk_overlap = 50,)\n",
    "\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预训练模型下载地址\n",
    "https://hf-mirror.com/BAAI/bge-m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"bge-m3\",\n",
    "    model_kwargs = {'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\n",
    ")\n",
    "\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_prompt = \"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "contexts:\n",
    "{source_knowledge}\n",
    "\n",
    "query: {query}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=augmented_prompt, input_variables=[\"source_knowledge\" ,\"query\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm  , llm_kwargs = {\"temperature\":0, \"max_length\":1024})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"问题\"\n",
    "result_simi = db.similarity_search(query , k=3)\n",
    "source_knowledge = \"\\n\".join([x.page_content for x in result_simi])\n",
    "print(llm_chain.run( {\"source_knowledge\":source_knowledge ,\"query\" : query }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**测试** \\\n",
    "测试在问答对.xlsx上的准确率"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
